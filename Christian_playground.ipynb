{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os, zipfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Preprocessing</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in data\n",
    "train_df = pd.read_csv('./train_onelabel.csv')\n",
    "train_images_paths = ['./train_images/' + p for p in train_df.image]\n",
    "train_labels = train_df['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24204, 64, 64, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create image matrix\n",
    "train_images = (load_img(p, target_size=(64, 64)) for p in train_images_paths)\n",
    "train_images = [img_to_array(img)[:, :, [0]] for img in train_images]\n",
    "train_images = np.array(train_images)\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preprocessing of labels\n",
    "classes = len(np.unique(train_labels))\n",
    "train_labels = to_categorical(train_labels, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split data into test and train set\n",
    "x_train, x_val, y_train,  y_val = train_test_split(train_images, train_labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize image data\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "x_train /= 255\n",
    "x_val /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialising the CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 1 - Convolution ---TODO: see input specification\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 1),padding='same', activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding a second convolutional layer+pooling layer\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu', padding='same'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Step 4 - Create a fully connected neural network\n",
    "'''its good practise to pick a number of power of two-experimenting output_dim\n",
    "128 hidden nodes in hidden layers-by experimenting'''\n",
    " \n",
    "#output_dim = number of nodes in the hidden layer\n",
    "classifier.add(Dense(units= 128, activation = 'relu'))\n",
    "\n",
    "#Dropout (p was used in the old API, changed it to the new standard)\n",
    "classifier.add(Dropout(rate = 0.2))\n",
    "\n",
    "#second hidden layer\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "\n",
    "\n",
    "#output layer\n",
    "classifier.add(Dense(units = 121, activation = 'softmax')) #We have 121 categories of plankton!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\movetech\\Anaconda2\\envs\\py35\\lib\\site-packages\\keras\\models.py:874: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "19363/19363 [==============================] - 139s 7ms/step - loss: 3.7981 - acc: 0.1419\n",
      "Epoch 2/25\n",
      "19363/19363 [==============================] - 145s 7ms/step - loss: 2.8355 - acc: 0.2832\n",
      "Epoch 3/25\n",
      "19363/19363 [==============================] - 152s 8ms/step - loss: 2.4937 - acc: 0.3383\n",
      "Epoch 4/25\n",
      "19363/19363 [==============================] - 155s 8ms/step - loss: 2.3212 - acc: 0.3722\n",
      "Epoch 5/25\n",
      "19363/19363 [==============================] - 154s 8ms/step - loss: 2.2131 - acc: 0.3926\n",
      "Epoch 6/25\n",
      "19363/19363 [==============================] - 163s 8ms/step - loss: 2.1251 - acc: 0.4080\n",
      "Epoch 7/25\n",
      "19363/19363 [==============================] - 153s 8ms/step - loss: 2.0612 - acc: 0.4221\n",
      "Epoch 8/25\n",
      "19363/19363 [==============================] - 149s 8ms/step - loss: 1.9909 - acc: 0.4394\n",
      "Epoch 9/25\n",
      "19363/19363 [==============================] - 133s 7ms/step - loss: 1.9332 - acc: 0.4502\n",
      "Epoch 10/25\n",
      "19363/19363 [==============================] - 167s 9ms/step - loss: 1.8825 - acc: 0.4592\n",
      "Epoch 11/25\n",
      "19363/19363 [==============================] - 132s 7ms/step - loss: 1.8380 - acc: 0.4716\n",
      "Epoch 12/25\n",
      "19363/19363 [==============================] - 148s 8ms/step - loss: 1.7892 - acc: 0.4810\n",
      "Epoch 13/25\n",
      "19363/19363 [==============================] - 133s 7ms/step - loss: 1.7646 - acc: 0.4914\n",
      "Epoch 14/25\n",
      "19363/19363 [==============================] - 135s 7ms/step - loss: 1.7241 - acc: 0.4989\n",
      "Epoch 15/25\n",
      "19363/19363 [==============================] - 136s 7ms/step - loss: 1.6943 - acc: 0.5070\n",
      "Epoch 16/25\n",
      "19363/19363 [==============================] - 135s 7ms/step - loss: 1.6426 - acc: 0.5162\n",
      "Epoch 17/25\n",
      "19363/19363 [==============================] - 135s 7ms/step - loss: 1.6277 - acc: 0.5212\n",
      "Epoch 18/25\n",
      "19363/19363 [==============================] - 135s 7ms/step - loss: 1.5991 - acc: 0.5260\n",
      "Epoch 19/25\n",
      "19363/19363 [==============================] - 135s 7ms/step - loss: 1.5484 - acc: 0.5436\n",
      "Epoch 20/25\n",
      "19363/19363 [==============================] - 135s 7ms/step - loss: 1.5184 - acc: 0.5459\n",
      "Epoch 21/25\n",
      "19363/19363 [==============================] - 136s 7ms/step - loss: 1.4907 - acc: 0.5527\n",
      "Epoch 22/25\n",
      "19363/19363 [==============================] - 133s 7ms/step - loss: 1.4577 - acc: 0.5594\n",
      "Epoch 23/25\n",
      "19363/19363 [==============================] - 134s 7ms/step - loss: 1.4645 - acc: 0.5622\n",
      "Epoch 24/25\n",
      "19363/19363 [==============================] - 131s 7ms/step - loss: 1.4129 - acc: 0.5759\n",
      "Epoch 25/25\n",
      "19363/19363 [==============================] - 145s 7ms/step - loss: 1.3860 - acc: 0.5790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21b28903a20>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model on training data\n",
    "classifier.fit(x_train, y_train, batch_size=80, nb_epoch=25, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = classifier.evaluate(x_val, y_val, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.6934762700139381, 0.53232803144772123]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.6067611749840531, 0.55009295603776365]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Save Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "# serialize model to JSON\n",
    "best_model_classification_json = classifier.to_json()\n",
    "with open(\"best_model_4.json\", \"w\") as json_file:\n",
    "    json_file.write(best_model_classification_json)\n",
    "# serialize weights to HDF5\n",
    "classifier.save_weights(\"model_best.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Load Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('best_model_3.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "classifier = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "classifier.load_weights(\"model_best.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Prediction - First Approach</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in data\n",
    "test_df = pd.read_csv('./sample.csv')\n",
    "test_images_paths = ['./test_images/' + p for p in test_df['image']]\n",
    "test_images_names = [p for p in test_df['image']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6132, 64, 64, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create image matrix\n",
    "test_images = (load_img(p, target_size=(64, 64)) for p in test_images_paths)\n",
    "test_images = [img_to_array(img)[:, :, [0]] for img in test_images]\n",
    "test_images = np.array(test_images)\n",
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize image data\n",
    "test_images = test_images.astype('float32')\n",
    "test_images /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = classifier.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "\n",
    "for count, i in enumerate(result):\n",
    "    labels.append(np.argmax(result[count]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "#Create Final csv for the competition\n",
    "csv_list =  pd.DataFrame( OrderedDict( { 'image': pd.Series(test_images_names), 'class': pd.Series(labels) } ) )\n",
    "csv_list.to_csv('sample3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results1 = pd.read_csv('./sample1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90715.jpg</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>159631.jpg</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4294.jpg</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56548.jpg</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120979.jpg</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>139460.jpg</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>78510.jpg</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>102841.jpg</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>84208.jpg</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9591.jpg</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>117254.jpg</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>152598.jpg</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>149049.jpg</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>146084.jpg</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>37310.jpg</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>152812.jpg</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>71417.jpg</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>63562.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20690.jpg</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>106297.jpg</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>85794.jpg</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>14572.jpg</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>79727.jpg</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>68132.jpg</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>156128.jpg</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>282.jpg</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>111105.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>117665.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>51984.jpg</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>154920.jpg</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6102</th>\n",
       "      <td>33439.jpg</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6103</th>\n",
       "      <td>97765.jpg</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6104</th>\n",
       "      <td>96829.jpg</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6105</th>\n",
       "      <td>115273.jpg</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6106</th>\n",
       "      <td>76597.jpg</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6107</th>\n",
       "      <td>32587.jpg</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6108</th>\n",
       "      <td>62414.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6109</th>\n",
       "      <td>116335.jpg</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6110</th>\n",
       "      <td>99871.jpg</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6111</th>\n",
       "      <td>119616.jpg</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6112</th>\n",
       "      <td>65110.jpg</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6113</th>\n",
       "      <td>153443.jpg</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6114</th>\n",
       "      <td>58590.jpg</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6115</th>\n",
       "      <td>47860.jpg</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6116</th>\n",
       "      <td>151982.jpg</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6117</th>\n",
       "      <td>61570.jpg</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6118</th>\n",
       "      <td>20508.jpg</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6119</th>\n",
       "      <td>151360.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6120</th>\n",
       "      <td>67333.jpg</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6121</th>\n",
       "      <td>132828.jpg</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6122</th>\n",
       "      <td>55604.jpg</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6123</th>\n",
       "      <td>125366.jpg</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6124</th>\n",
       "      <td>103014.jpg</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6125</th>\n",
       "      <td>138964.jpg</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6126</th>\n",
       "      <td>78721.jpg</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6127</th>\n",
       "      <td>41950.jpg</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6128</th>\n",
       "      <td>31439.jpg</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6129</th>\n",
       "      <td>151022.jpg</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6130</th>\n",
       "      <td>30324.jpg</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6131</th>\n",
       "      <td>158893.jpg</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6132 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           image  class\n",
       "0      90715.jpg     17\n",
       "1     159631.jpg    101\n",
       "2       4294.jpg     34\n",
       "3      56548.jpg     61\n",
       "4     120979.jpg     40\n",
       "5     139460.jpg     24\n",
       "6      78510.jpg     89\n",
       "7     102841.jpg     34\n",
       "8      84208.jpg     17\n",
       "9       9591.jpg     53\n",
       "10    117254.jpg     42\n",
       "11    152598.jpg     80\n",
       "12    149049.jpg     58\n",
       "13    146084.jpg     72\n",
       "14     37310.jpg     70\n",
       "15    152812.jpg     94\n",
       "16     71417.jpg     26\n",
       "17     63562.jpg      4\n",
       "18     20690.jpg     28\n",
       "19    106297.jpg     42\n",
       "20     85794.jpg     24\n",
       "21     14572.jpg     92\n",
       "22     79727.jpg     56\n",
       "23     68132.jpg     46\n",
       "24    156128.jpg     70\n",
       "25       282.jpg     92\n",
       "26    111105.jpg      8\n",
       "27    117665.jpg     12\n",
       "28     51984.jpg     80\n",
       "29    154920.jpg     35\n",
       "...          ...    ...\n",
       "6102   33439.jpg     21\n",
       "6103   97765.jpg     45\n",
       "6104   96829.jpg     21\n",
       "6105  115273.jpg     34\n",
       "6106   76597.jpg     24\n",
       "6107   32587.jpg     21\n",
       "6108   62414.jpg      8\n",
       "6109  116335.jpg     34\n",
       "6110   99871.jpg    119\n",
       "6111  119616.jpg     21\n",
       "6112   65110.jpg     34\n",
       "6113  153443.jpg     92\n",
       "6114   58590.jpg    119\n",
       "6115   47860.jpg    119\n",
       "6116  151982.jpg    119\n",
       "6117   61570.jpg     34\n",
       "6118   20508.jpg     58\n",
       "6119  151360.jpg      1\n",
       "6120   67333.jpg     45\n",
       "6121  132828.jpg     61\n",
       "6122   55604.jpg     11\n",
       "6123  125366.jpg      8\n",
       "6124  103014.jpg     53\n",
       "6125  138964.jpg     18\n",
       "6126   78721.jpg    119\n",
       "6127   41950.jpg    119\n",
       "6128   31439.jpg     34\n",
       "6129  151022.jpg     34\n",
       "6130   30324.jpg     34\n",
       "6131  158893.jpg     53\n",
       "\n",
       "[6132 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Prediction - Second Approach </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from collections import OrderedDict\n",
    "\n",
    "def find_category(path):\n",
    "    \n",
    "    test_image = image.load_img(path, target_size = (32, 32),grayscale = True)\n",
    "    test_image = image.img_to_array(test_image)\n",
    "  \n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "    result = classifier.predict(test_image)\n",
    "    \n",
    "    #training_set.class_indices\n",
    "    \n",
    "    \n",
    "    category = int(np.where(result[0]!=0)[0][0])\n",
    "    return category\n",
    "    \n",
    "\n",
    "images = []\n",
    "categories = []\n",
    "path = 'test_images/'\n",
    "\n",
    "for count,i in enumerate(os.listdir(path)):\n",
    "    \n",
    "    images.append(str(i)) #save image name\n",
    "    \n",
    "    image_path = path+str(i)\n",
    "\n",
    "    category = find_category(image_path)\n",
    "    \n",
    "    categories.append(category) #saves the category of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "categories = []\n",
    "path = 'test_images/'\n",
    "\n",
    "for count,i in enumerate(os.listdir(path)):\n",
    "    \n",
    "    images.append(str(i)) #save image name\n",
    "    \n",
    "    image_path = path+str(i)\n",
    "\n",
    "    category = find_category(image_path)\n",
    "    \n",
    "    categories.append(category) #saves the category of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create Final csv for the competition\n",
    "csv_list =  pd.DataFrame( OrderedDict( { 'image': pd.Series(images), 'class': pd.Series(categories) } ) )\n",
    "csv_list.to_csv('sample2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results2 = pd.read_csv('./sample2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comparison = results1.merge(results2, on='image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different results: 5738\n"
     ]
    }
   ],
   "source": [
    "print('Number of different results: ' + str(len(comparison[comparison['class_x'] != comparison['class_y']])))ka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py35",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
